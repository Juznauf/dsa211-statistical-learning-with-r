---
title: "A3 redo"
output: html_notebook
---



Question 1
1. The business problem facing the director of broadcasting operations for a television station was the issue of standby hours (i.e. hours in which unionized graphic artists at the station are paid but are not actually involved in any activity) and what factors were related to standby hours. The study included the following variables:
Standby hour (Y ): Total number of standby hours in a week Total staﬀ present (X1): Weekly total of people-days Remote hours (X2): Total number of hours worked by employees at locations away from the central plant
Data were collected and stored in Standby2020.csv.


(a) Plot the graph to show all the pairwise relationships among Y , X1 and X2. Are X1 and X2 highly correlated, based on the graph? Explain. 

```{r}
standby <- read.csv("D:/User/Documents/SMU CONTENT/Year 3 Sem 2/DSA 211/All Assignments/Assignment/Standby2020.csv")

pairs(standby)


```

Yes, they are highly correlated as there is a negative linear relationship shown in the graph. 


(b) Find the multiple regression equation L1 with X1 and X2 as main independent variables. 

```{r}
names(standby)
lm.l1 <- lm(Standby~. ,data = standby)
coef(lm.l1)
```

L1: Standby=-69.834+0.853Staff+0.0898Remote 

(c) Find the multiple regression equation L2 with two main independent variables and their interaction eﬀect.

```{r}
lm.l2 <- lm(Standby~ Staff*Remote ,data = standby)
coef(lm.l2)
```

L2: Standby=-56.097+0.808Staff-0.374Remote+0.00152Staff*Remote 

(d) Find the simple regression equation L3 with the main independent variable X1 only.
```{r}

lm.l3 <- lm(Standby~ Staff,data = standby)
coef(lm.l3)
```

L3: Standby=-61.79615+0.83534Staff 

(e) When comparing all three regression models: L1,L2,L3, explain why model L3 is the best model. 

```{r}
summary(lm.l1)
summary(lm.l2)
summary(lm.l3)
```

L3 is the best model since L3 has the highest adjusted R-squared 0.9513 while L1 has 0.9503 and L2 has 0.9493. 


(f) Perform a residual analysis on the model L3 and determine whether the regression assumptions are valid. 



```{r}
library(fitdistrplus)
plot(residuals(lm.l3), standby$Staff, main="Relationship between Staff and residuals", xlab="Staff", ylab="residuals")
fnorm <- fitdist(residuals(lm.l3), distr="norm")

result <- gofstat(fnorm, discrete = FALSE)
result
plot(fnorm)



```

Based on the residual analysis, we have no reason to doubt the regression assumptions. 


(g) Construct a 99% conﬁdence interval estimate for the mean standby hours for weeks in which the total staﬀ present have 310 people-days and the remote hours are 32 in model L3. 


```{r}
predict(lm.l3, data.frame(Staff = 310, Remote = 32), interval = "confidence",level = 0.99)
```



99% conﬁdence interval is (195.8238, 198.4937)



h) Construct a 99% prediction interval estimate for the standby hours for a single week in which the total staﬀ present has 305 people-days and the remote hours are 33 in model L3.


```{r}
predict(lm.l3, data.frame(Staff = 305, Remote = 33), interval = "prediction",level = 0.99)
```



99% prediction interval is (184.0024, 201.9618)



2. The owner of a moving company typically has his most experienced manager predict the total number of labor hours (Hours) that will be required to complete an upcoming move. This approach has proved useful in the past, but the owner has the business objective of developing a more accurate method of predicting labor hours. In a preliminary eﬀort to provide a more accurate method, the owner has decided to use the number of cubic feet moved (Feet), the number of pieces of large furniture (Large) and whether there is an elevator in the apartment building (Elevator) as the independent variables and has collected data for moves in which the origin and destination were within the borough of Manhattan in New York City and the travel time was an insigniﬁcant portion of the hours worked. The data are organized and stored in Moving2020.csv.

```{r}
Moving <- read.csv("D:/User/Documents/SMU CONTENT/Year 3 Sem 2/DSA 211/All Assignments/Assignment/Moving2020.csv")

names(Moving)

```



```{r}
RNGkind(sample.kind = "Rounding")
```


(a) Find the multiple regression equation L1 with all the three main independent variables. 

```{r}
lm.l1 <- lm(Hours~., data = Moving)
coef(lm.l1)
```

L1: Hours=13.516+0.0217Feet+1.6432Large-4.496Elevator(Y) 

(b) Find the multiple regression equation L2 with all the three main independent variables with the interaction eﬀect of Feet and Elevator. 


```{r}

lm.l2 <- lm(Hours~Large + Feet* Elevator, data = Moving)
coef(lm.l2)
```

L2: Hours=11.003+0.0253Feet+1.6221Large-1.105Elevator(Y)0.0052Feet:Elevator(Y) 

(c) Find the multiple regression equation L3 with all the three main independent variables with the interaction eﬀect of Large and Elevator. 

```{r}

lm.l3 <- lm(Hours~Feet + Large*Elevator, data = Moving)
coef(lm.l3)
```
L3: Hours=10.2677+0.0214Feet+2.6066Large+0.0207Elevator(Y)1.4128Large:Elevator(Y) 



(d) Find the multiple regression equation L4 with all the three main independent variables with the interaction eﬀect of Feet and Large.


```{r}
lm.l4 <- lm(Hours~Elevator + Feet*Large, data = Moving)
coef(lm.l4)

```

L4: Hours=16.866+0.0139Feet+0.3042Large4.1499Elevator(Y)+0.002614Large:Feet 

(e) When comparing all four regression models: L1,L2,L3,L4, explain why model L3 is the best model. 

```{r}
summary(lm.l1)
summary(lm.l2)
summary(lm.l3)
summary(lm.l4)
```


L3 is the best model because it has the largest adjusted R squared 0.866. 



(f) Perform a residual analysis on the model L3 and determine whether the regression assumptions are valid. 

```{r}
plot(lm.l3$fitted.values, residuals(lm.l3) , main = "Relationship between predicted Hours and residuals", xlab = "Predicted Labor Hours", ylab = "residuals")
```



```{r}
pairs(cbind(residuals(lm.l3), Moving[-c(1,4)]))
```



```{r}
fnorm <- fitdist(residuals(lm.l3), distr = "norm")
plot(fnorm)
```


Based on the residual analysis, we have no reason to doubt the regression assumptions. 



(g) Construct a 95% prediction interval estimate for the labor hours for moving 410 cubic feet with 2 large furniture in an apartment building that does not have an elevator in model L3 


```{r}

names(Moving)
predict(lm.l3, data.frame(Feet = 410, Large = 2, Elevator = "No"),
   interval = "prediction", level = 0.95)
```

(18.32, 30.21) hours 

(h) Construct a 95% conﬁdence interval estimate for the average labor hours for moving 420 cubic feet with 3 large furniture in an apartment building that has an elevator in model L3


```{r}

predict(lm.l3, data.frame(Feet = 420, Large = 3, Elevator = "Yes"),
   interval = "confidence", level = 0.95)
```

(21.83, 23.90) hours 



(i) True or False: For a ﬁxed value of cubic feet and at least one large furniture situations, the total number of labor hours to move in the building with elevator is on average less than the number of labor hours to move in the building without elevator under model L3. Justify your answer.


```{r}
coef(lm.l3)
```

True as the coefficient of Elevator with at least one large furniture is negative.


TRUE.  Under L3:  with elevator Hours=10.2884+0.0214Feet+1.1938Large, but without elevator Hours=10.2677+0.0214Feet+2.6066Large.  Therefore, the estimated time saved is 1.4128Large-0.0207> 0 for Large >0.   


3. The director of undergraduate studies at a college of business wants to predict whether students in a BBA program can graduate with a honor degree using independent variables, High school grade point average (GPA), SAT score, gender, and local citizen. Data from a random sample of 90 students, organized and stored in BBA2020.csv, show that 46 successfully completed the program with honor degrees (coded as Yes) and 44 without honor degrees (coded as No) under the variable column Graduate.

```{r}
BBA <- read.csv("D:/User/Documents/SMU CONTENT/Year 3 Sem 2/DSA 211/All Assignments/Assignment/BBA2020.csv")
names(BBA)
```




(a) Develop a logistic regression model, L1, to predict the probability of successfully completed the BBA program with honor degrees, based on all independent variables



```{r}
glm.l1 <- glm(Graduate~. , data = BBA, family = 'binomial')
summary(glm.l1)

```


Log(odds ratio)=-41.7368-0.2101GPA+0.0325-SAT0.3916Gender(M)+0.5833Local(Yes) 


(b) Develop the other logistic regression model, L2, to predict the probability of successfully completed the BBA program with honor degrees, based on the SAT, Gender, and Local independent variables. 

```{r}

glm.l2 <- glm(Graduate~.-GPA , data = BBA, family = 'binomial')
summary(glm.l2)


```

Log(odds ratio)=-41.7867+0.0321SAT-0.4131Gender(M)+0.5817Local(Yes) 


(c) Develop the other logistic regression model, L3, to predict the probability of successfully completed the BBA program, based on the SAT and Local independent variables. 

```{r}

glm.l3 <- glm(Graduate~ SAT + Local, data = BBA, family = "binomial")
summary(glm.l3)

```


Log(odds ratio)=-42.8384+0.0328SAT+0.6729Local(Yes) 


(d) Develop the other logistic regression model, L4, to predict the probability of successfully completed the BBA program, based on the SAT independent variables.

```{r}
glm.l4 <- glm(Graduate~ SAT , data = BBA, family = "binomial")
summary(glm.l4)

```


Log(odds ratio)=-41.5074+0.0319SAT 


(e) Explain why model L4 is the best model among the four models considered. At the 0.05 level of signiﬁcance, is there evidence that a logistic regression model L4 is a good ﬁtting model? 

```{r}
pvalue <- 1 - pchisq(51.672, 88)
pvalue
```


Model L4 has the lowest AIC. As the chi sq p -value is more than the significance level, cannot reject the logistic model. Insufficient evidence that the logistic regression model L4 is a good fitting model 


The AIC of L1, L2, L3 and L4 are 60.59, 58.62, 56.93 and 55.67, respectively. L4 is the best model due to the smallest of AIC.  Since the p-value of testing L4 model is 0.9992, we can’t reject null hypothesis.  The data do not provide sufficient evidence to doubt about L4 is not a good model.



(f) Predict the probability of successfully completed the BBA program with honor degree given that a female local citizen with GPA 3.40 and SAT score 1340 under model L4. 


```{r}


predict(glm.l4, data.frame(GPA = 3.4, SAT = 1340), type="response")

```


The probability of successfully completed the BBA program with honor degree given that a female local citizen with GPA 3.40 and SAT score 1340 under model L4 is 0.778701 



(g) Find the confusion matrix of model L4 with the threshold value 0.6 for classifying students successfully completed the BBA program with honor degrees. 



```{r}
glm.prob1 <- predict(glm.l4, type="response")
glm.pred1.1 <- rep("Predicted Not Completed", length(BBA$GPA))
glm.pred1.1[glm.prob1> 0.6] <- "Predicted Completed"
Graduate <- BBA$Graduate
table1 <- table(glm.pred1.1, Graduate)
table1
```


(h) Find the sensitivity, speciﬁcity and total error rate of the model L4 with the threshold value 0.6.


```{r}
# calculate the sensitivity = TP/(TP + FN)

sensitivity <- table1[1,2]/sum(table1[,2])
sensitivity
```

The sensitivity is 0.8478261

```{r}
# calculate the specificity = TN/(TN + FP)

specificity <- table1[2,1]/sum(table1[,1])
specificity
```

The specificity is  0.8863636

```{r}
# calculate the overall error rate = (FP + FN)/N

overall.error.rate <- sum(table1[1,1],table1[2,2])/sum(table1)
overall.error.rate
```



the overall error rate is  0.1333333


The sensitivity is 0.8478; the specificity is 0.8864 and total error is 0.1333. 






4. Suppose we collect data for a group of 130 students in a statistical class with two independent variables X1 = average studying hours per week, X2 = GPA, and one dependent variable Y = Pass (or Fail). We ﬁt a logistic regression model: log(odds ratio) = β0 + β1X1 + β2X2 to predict whether a student will pass the course. R-outputs produce estimated coeﬃcients, ˆ β0 = −9.5447, ˆ β1 = 0.5720, and ˆ β2 = 1.0694. The observations of the ﬁrst ﬁve students are given as follows:


(a) Based on the estimated logistic regression model, predict the probability that a student who studies 11 hours per week on average and has a GPA of 3.40 will pass the course. 


```{r}
beta0 <- -9.5447
beta1 <- 0.5720
beta2 <- 1.0694
ff <- function(beta0, beta1, beta2, x1, x2) {
  aa <- exp(beta0+beta1*x1+ beta2*x2)
  ff <- aa/(1+aa)
  ff # probabilty of default given x
}


x1 <- c(9.4, 14.5, 12.2, 8.4,11.3)
x2 <- c(3.04, 3.42, 3.16, 2.78,3.10)
y1 <- c("Pass","Pass","Pass", "Fail", "Fail")

data1 <- data.frame(y1, x1, x2)



# pred1 <- (exp(beta0 + beta1*11 + beta2*3.4))/(1 + exp(beta0 + beta1*11 + beta2*3.4))
pred1 <- ff(beta0, beta1, beta2, 11,3.4)
pred1


```



the probability that a student who studies 11 hours per week on average and has a GPA of 3.40 will pass the course is 0.5946591



(b) At least how many hours would the student in part (a) need to study to have more than 70% predicted chance of passing the course? 



```{r}
# let the pred == 0.7, solve for x1,


study <- ((log(0.7/0.3)) - beta0 - beta2*3.4)/beta1 
study
```

The student needs at least  11.81 hours 


(c) Find the deviance residues of the ﬁrst ﬁve observed students.



```{r}


ff <- function(beta0, beta1, beta2, x1, x2) {
  aa <- exp(beta0+beta1*x1+ beta2*x2)
  ff <- aa/(1+aa)
  ff # probabilty of default given x
}



pos <- function(pred) {
  d1 <- sqrt(2*-log(1-(1-pred)))
}
nev <- function(pred) {
  d2 <- -sqrt(2*-log(1-(pred-0)))
}



```








```{r}
res.dev <- NULL
for (i in 1:5) {
  est <-ff(beta0, beta1, beta2, x1[i], x2[i])
  res.dev[i] <- ifelse(y1[i] == "Pass", pos(est), nev(est)) 
}
res.dev
```

The five deviance residues are 1.5832, 0.4154, 0.8568, -0.5617, and  -1.2783, respectively. 



(d) By using the estimated logistic regression model with the threshold value being 0.55 for classiﬁcation of passing the course, determine whether the model makes any error to predict each of the above ﬁve observed students. If there is an error, determine what type of error as well.

```{r}

pred1 <- NULL

for (i in 1:5) {
  
  pred1[i] <-ff(beta0, beta1, beta2, x1[i], x2[i])
}

pred1

d1 <- data.frame(cbind(y1, x1,x2,pred1) )  
d1
```


The model makes a FN error for student 1, and a FP error for student 5.












